experiment:
  name: "n5_gohrnet_4x32_ft_n4"
  output_dir: "output/tea"
  # seed: 42

data:
  path: "data/tea_n5"

processor:
  swap_pairs: false
  xor_channel: false
  reshape: [4, 32]
  normalize: true

model:
  type: "GohrNet"
  params:
    length: 32
    in_channels: 4
    n_filters: 32
    n_blocks: 10
    d1: 64
    d2: 64

training:
  epochs: 20
  batch_size: 5000
  num_workers: 24
  eval_interval: 5
  checkpoint_interval: 5
  device: "cuda:1"
  use_amp: true
  pretrained: "output/tea/n4_gohrnet_4x32_20260201_061747/checkpoint_10.pth"

  loss:
    type: "BCEWithLogitsLoss"
    params: {}
  
  optimizer:
    type: "AdamW"
    params:
      lr: 2e-3
      betas: [0.9, 0.999]
      weight_decay: 1e-5
  
  scheduler:
    type: "CosineAnnealingWarmRestarts"
    params:
      T_0: 18000
      T_mult: 1
      eta_min: 1e-4