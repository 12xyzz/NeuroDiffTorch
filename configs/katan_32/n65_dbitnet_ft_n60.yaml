experiment:
  name: "n65_dbitnet_1x64_ft_n60"
  output_dir: "output/katan_32"
  # seed: 42

data:
  path: "data/katan_32_n65"

processor:
  swap_pairs: false
  xor_channel: false
  reshape: [1, 64]
  normalize: true

model:
  type: "DBitNet"
  params:
    length: 64
    in_channels: 1
    d1: 256
    d2: 64
    n_filters: 32
    n_add_filters: 16

training:
  epochs: 20
  batch_size: 5000
  num_workers: 24
  eval_interval: 5
  checkpoint_interval: 5
  device: "cuda:0"
  use_amp: true
  pretrained: "output/katan_32/n60_dbitnet_1x64_ft_n55_20260202_125203/checkpoint_5.pth"

  loss:
    type: "BCEWithLogitsLoss"
    params: {}

  optimizer:
    type: "AdamW"
    params:
      lr: 1e-3
      betas: [0.9, 0.999]
      weight_decay: 1e-5